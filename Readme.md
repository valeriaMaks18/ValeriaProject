## Описание проекта

Заказчик проекта - «Бета-Банк».

«Бета-Банк» столкнулся с проблемой оттока клиентов. Ежемесячно наблюдается постоянный и достаточно значимый уровень оттока.

По ценкам демартамента  маркетинга банка стоимость сохранения текущих клиентов дешевле, чем привлечения новых.

Результатом проекта является модель способная спрогнозировать уйдёт клиент из банка в ближайшее время или нет.

Для построениея модели будут использоваться исторические данные о поведении клиентов и расторжении договоров с банком.

Целевая модель должна соотвествовать следующим критериям качества:

- F1-меры должная быть не менее 0.59.

### Описание структуры данных

- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата

Целевой признак

- Exited — факт ухода клиента

**Построение моделей без учёта дисбаланса классов**

    Для построения моделей мы использовали следущие алгоритмы обучения:
     - LogisticRegression
     - DecisionTreeClassifier
     - RandomForestClassifier

    При тестировании готовых моделей были достигнуты следущие результаты меры F1:
     - LogisticRegression: 0.2932960893854748
     - DecisionTreeClassifier: 0.48022079116835326
     - RandomForestClassifier: 0.5680473372781064

    Без решения проблемы балансировки классов целевой проектный показатель меры F1 не был достигнут.

**Решение проблемы дисбаланса классов**

    1. Применение параметра `class_weight` хотя и позволило улучшить значение меры F1,
    не позволило достичь целевого проектного показателя:

     - LogisticRegression:
     - `class_wright = balanced`,  F1 = 0.5114709851551956

     - DecisionTreeClassifier:
     - `class_weight = {1: 0.8, 0: 0.2}`, F1 = 0.5

     - RandomForestClassifier:
     -  `class_weight = {1: 0.8, 0: 0.2}`, F1 = 0.5741399762752076

     Приведённые выше значения параметра `class_weight` дают оптимальные значения мера F1
     при текущей конфигурации данных и гиперпатаметров алгоритмов обучения

     2. Применение метода `upsampling`:

     - LogisticRegression:
     - `class_wright = balanced`,  F1 = 0.5114709851551956

     - DecisionTreeClassifier:
     - `class_weight = None`, F1 = 0.50332383665717

     - RandomForestClassifier:
     -  `class_weight = balanced`, F1 = 0.6164948453608248


     Оптимальный фактор увеличения - 4

     Применение метода `upsampling` позволило достичь и превысить целевой проектный показатель
     меры F1 для алгоритма RandomForestClassifier

     3.  Применение метода `downsampling`:

      - LogisticRegression:
      - `class_weight = None`,  F1 = 0.45959104186952293

     - DecisionTreeClassifier:
     - `class_weight = balanced`, F1 = 0.49550286181520853

     - RandomForestClassifier:
     -  `class_weight = balanced`, F1 = 0.6181818181818182


     Оптимальный фактор уменьшения - 0.5

     Применение метода `downsampling` позволило достичь и превысить целевой проектный показатель
     меры F1 для алгоритма RandomForestClassifier. Также метод downsample позволил достичь незначительно лучшего значения меры F1

     4. Выборочное применение других методов ребалансировки данных:

     - `SMOTE` позволил несколько улучшить показатель F1 по сравнению с нашим начальным oversample подходом:
    0.6178403755868545 (было достигнуто также 0.6221335992023929) vs 0.6164948453608248

    - `CondensedNearestNeighbour` позволил несколько улучшить показатель F1 по сравнению
    с нашим начальным downsample подходом:

    F1: 0.6190885640584695 vs 0.6181818181818182

     В качестве алгоритма обучения использовался только случайный лес, как наиболее качественный алгоритм

**Оценка адекватности целевой модели**

    Целевые модели показали лучшие результаты чем `DummyClassifier`, можем признать наши модели адекватными

**Исследование метрики AUC-ROC**

    - Кривая ROC нашей целевой модели тяготеет к 'идеальному' левому верхнему углу и соотвественно
    демонстрирует приемлемое качество работы модели.











